{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sustainable AI Energy Consumption Prediction Model\n",
    "\n",
    "This notebook demonstrates a sustainable approach to building an energy consumption prediction model. It includes:\n",
    "\n",
    "1. Data loading and preprocessing\n",
    "2. Feature engineering and selection\n",
    "3. Model training with energy efficiency constraints\n",
    "4. Evaluation with both performance and sustainability metrics\n",
    "5. Visualization of results\n",
    "\n",
    "The model follows sustainable AI principles by:\n",
    "- Tracking energy consumption during training\n",
    "- Optimizing for model efficiency\n",
    "- Providing interpretability\n",
    "- Balancing performance with resource usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, let's install the required packages and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost shap psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Consumption Tracking\n",
    "\n",
    "Let's create a class to track energy consumption during model training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class EnergyTracker:\n",
    "    \"\"\"Tracks energy consumption of AI model training and inference.\"\"\"\n",
    "    \n",
    "    def __init__(self, device_type='cpu', power_consumption_watts=None):\n",
    "        \"\"\"Initialize the energy tracker.\n",
    "        \n",
    "        Args:\n",
    "            device_type: Type of computing device ('cpu', 'gpu')\n",
    "            power_consumption_watts: Optional override for device power consumption\n",
    "        \"\"\"\n",
    "        self.device_type = device_type.lower()\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.duration_seconds = 0\n",
    "        self.total_energy_kwh = 0\n",
    "        \n",
    "        # Set default power consumption based on device type if not provided\n",
    "        if power_consumption_watts is None:\n",
    "            if self.device_type == 'cpu':\n",
    "                self.power_consumption_watts = 65  # Average CPU power consumption\n",
    "            elif self.device_type == 'gpu':\n",
    "                self.power_consumption_watts = 250  # Average GPU power consumption\n",
    "            else:\n",
    "                self.power_consumption_watts = 100  # Default for unknown devices\n",
    "        else:\n",
    "            self.power_consumption_watts = power_consumption_watts\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        self.tracking_history = []\n",
    "        self.cpu_percent_history = []\n",
    "        self.memory_percent_history = []\n",
    "    \n",
    "    def start_tracking(self):\n",
    "        \"\"\"Start tracking energy consumption.\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        self.cpu_percent_history = []\n",
    "        self.memory_percent_history = []\n",
    "    \n",
    "    def stop_tracking(self):\n",
    "        \"\"\"Stop tracking energy consumption and calculate metrics.\"\"\"\n",
    "        if self.start_time is None:\n",
    "            raise ValueError(\"Tracking was not started. Call start_tracking() first.\")\n",
    "        \n",
    "        self.end_time = time.time()\n",
    "        self.duration_seconds = self.end_time - self.start_time\n",
    "        \n",
    "        # Calculate energy consumption in kilowatt-hours\n",
    "        # Power (W) * Time (h) / 1000 = Energy (kWh)\n",
    "        self.total_energy_kwh = (self.power_consumption_watts * self.duration_seconds / 3600) / 1000\n",
    "        \n",
    "        # Calculate average CPU and memory usage\n",
    "        avg_cpu_percent = np.mean(self.cpu_percent_history) if self.cpu_percent_history else 0\n",
    "        avg_memory_percent = np.mean(self.memory_percent_history) if self.memory_percent_history else 0\n",
    "        \n",
    "        # Record tracking session\n",
    "        session_data = {\n",
    "            'device_type': self.device_type,\n",
    "            'power_consumption_watts': self.power_consumption_watts,\n",
    "            'duration_seconds': self.duration_seconds,\n",
    "            'energy_consumption_kwh': self.total_energy_kwh,\n",
    "            'avg_cpu_percent': avg_cpu_percent,\n",
    "            'avg_memory_percent': avg_memory_percent,\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        self.tracking_history.append(session_data)\n",
    "        \n",
    "        return session_data\n",
    "    \n",
    "    def monitor_resources(self):\n",
    "        \"\"\"Monitor CPU and memory usage during tracking.\"\"\"\n",
    "        if self.start_time is not None:\n",
    "            self.cpu_percent_history.append(psutil.cpu_percent())\n",
    "            self.memory_percent_history.append(psutil.virtual_memory().percent)\n",
    "    \n",
    "    def get_carbon_footprint(self, region='global', renewable_percentage=0):\n",
    "        \"\"\"Calculate carbon footprint based on energy consumption.\n",
    "        \n",
    "        Args:\n",
    "            region: Geographic region for carbon intensity calculation\n",
    "            renewable_percentage: Percentage of energy from renewable sources (0-100)\n",
    "            \n",
    "        Returns:\n",
    "            Carbon footprint in kg CO2 equivalent\n",
    "        \"\"\"\n",
    "        # Carbon intensity of electricity by region (kg CO2 per kWh)\n",
    "        carbon_intensity = {\n",
    "            'global': 0.475,\n",
    "            'us': 0.417,\n",
    "            'eu': 0.275,\n",
    "            'china': 0.555,\n",
    "            'india': 0.708,\n",
    "            'canada': 0.135,\n",
    "            'uk': 0.233,\n",
    "            'france': 0.056,\n",
    "            'germany': 0.338\n",
    "        }\n",
    "        \n",
    "        # Get carbon intensity for the specified region\n",
    "        intensity = carbon_intensity.get(region.lower(), carbon_intensity['global'])\n",
    "        \n",
    "        # Apply renewable energy percentage\n",
    "        effective_intensity = intensity * (1 - renewable_percentage / 100)\n",
    "        \n",
    "        # Calculate carbon footprint\n",
    "        return self.total_energy_kwh * effective_intensity\n",
    "    \n",
    "    def plot_energy_consumption(self):\n",
    "        \"\"\"Plot energy consumption history.\"\"\"\n",
    "        if not self.tracking_history:\n",
    "            print(\"No tracking history available.\")\n",
    "            return\n",
    "        \n",
    "        # Extract data for plotting\n",
    "        labels = [f\"Session {i+1}\" for i in range(len(self.tracking_history))]\n",
    "        energy_values = [session['energy_consumption_kwh'] for session in self.tracking_history]\n",
    "        durations = [session['duration_seconds'] for session in self.tracking_history]\n",
    "        \n",
    "        # Create figure with two subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Plot energy consumption\n",
    "        bars1 = ax1.bar(labels, energy_values, color='skyblue')\n",
    "        ax1.set_xlabel('Training Session')\n",
    "        ax1.set_ylabel('Energy Consumption (kWh)')\n",
    "        ax1.set_title('Energy Consumption by Training Session')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars1:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.0001,\n",
    "                    f'{height:.6f}',\n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        # Plot duration\n",
    "        bars2 = ax2.bar(labels, durations, color='lightgreen')\n",
    "        ax2.set_xlabel('Training Session')\n",
    "        ax2.set_ylabel('Duration (seconds)')\n",
    "        ax2.set_title('Training Duration by Session')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars2:\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # If we have CPU and memory data, plot resource usage\n",
    "        if self.cpu_percent_history and self.memory_percent_history:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(self.cpu_percent_history, label='CPU Usage (%)', color='blue')\n",
    "            plt.plot(self.memory_percent_history, label='Memory Usage (%)', color='green')\n",
    "            plt.xlabel('Monitoring Interval')\n",
    "            plt.ylabel('Usage Percentage')\n",
    "            plt.title('Resource Usage During Training')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "\n",
    "Now, let's load the energy consumption dataset and explore its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload the CSV file\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload energy_consumption_data.csv\n",
    "\n",
    "# Load the dataset\n",
    "filename = list(uploaded.keys())[0]\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(df.dtypes)\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Let's preprocess the data by handling timestamps, missing values, and creating additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "display(df.isnull().sum())\n",
    "\n",
    "# Create additional time-based features\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['is_morning'] = (df['hour'] >= 6) & (df['hour'] < 12)\n",
    "df['is_afternoon'] = (df['hour'] >= 12) & (df['hour'] < 18)\n",
    "df['is_evening'] = (df['hour'] >= 18) & (df['hour'] < 22)\n",
    "df['is_night'] = (df['hour'] >= 22) | (df['hour'] < 6)\n",
    "\n",
    "# Create interaction features\n",
    "df['temp_humidity_interaction'] = df['temperature'] * df['humidity']\n",
    "df['occupancy_appliances_interaction'] = df['occupancy'] * df['appliances_in_use']\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(\"\\nUpdated dataframe with new features:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "Let's visualize the data to better understand the patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot energy consumption over time\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df['timestamp'], df['energy_consumption'], color='blue')\n",
    "plt.title('Energy Consumption Over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Energy Consumption (kWh)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot energy consumption by hour of day\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='hour_of_day', y='energy_consumption', data=df)\n",
    "plt.title('Energy Consumption by Hour of Day')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Energy Consumption (kWh)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot energy consumption by day of week\n",
    "plt.figure(figsize=(12, 6))\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(x='day_of_week', y='energy_consumption', data=df)\n",
    "plt.xticks(range(7), day_names)\n",
    "plt.title('Energy Consumption by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Energy Consumption (kWh)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "correlation = numeric_df.corr()\n",
    "mask = np.triu(correlation)\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', mask=mask)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot pairplot for key features\n",
    "key_features = ['temperature', 'humidity', 'occupancy', 'appliances_in_use', 'solar_generation', 'energy_consumption']\n",
    "sns.pairplot(df[key_features], height=2.5)\n",
    "plt.suptitle('Pairplot of Key Features', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Data Preparation\n",
    "\n",
    "Let's select the relevant features and prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select features for modeling\n",
    "features = [\n",
    "    'temperature', 'humidity', 'day_of_week', 'hour_of_day', 'is_weekend', 'is_holiday',\n",
    "    'occupancy', 'appliances_in_use', 'hvac_status', 'solar_generation',\n",
    "    'is_morning', 'is_afternoon', 'is_evening', 'is_night',\n",
    "    'temp_humidity_interaction', 'occupancy_appliances_interaction'\n",
    "]\n",
    "\n",
    "# Define target variable\n",
    "target = 'energy_consumption'\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with Energy Tracking\n",
    "\n",
    "Now, let's train different models while tracking their energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize energy tracker\n",
    "energy_tracker = EnergyTracker(device_type='cpu')\n",
    "\n",
    "# Function to train and evaluate a model with energy tracking\n",
    "def train_and_evaluate_model(model, model_name, X_train, y_train, X_test, y_test, energy_tracker):\n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # Start energy tracking\n",
    "    energy_tracker.start_tracking()\n",
    "    \n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Stop energy tracking\n",
    "    energy_metrics = energy_tracker.stop_tracking()\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate carbon footprint\n",
    "    carbon_footprint = energy_tracker.get_carbon_footprint(region='global', renewable_percentage=20)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nSustainability Metrics:\")\n",
    "    print(f\"Training Time: {training_time:.4f} seconds\")\n",
    "    print(f\"Energy Consumption: {energy_metrics['energy_consumption_kwh']:.6f} kWh\")\n",
    "    print(f\"Carbon Footprint: {carbon_footprint:.6f} kg CO2eq\")\n",
    "    \n",
    "    # Calculate model size (approximate)\n",
    "    import sys\n",
    "    model_size_bytes = sys.getsizeof(model)\n",
    "    print(f\"Model Size: {model_size_bytes / 1024:.2f} KB\")\n",
    "    \n",
    "    # Return metrics\n",
    "    return {\n",
    "        'model': model,\n",
    "        'model_name': model_name,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'training_time': training_time,\n",
    "        'energy_consumption': energy_metrics['energy_consumption_kwh'],\n",
    "        'carbon_footprint': carbon_footprint,\n",
    "        'model_size': model_size_bytes / 1024\n",
    "    }\n",
    "\n",
    "# Train different models\n",
    "models = [\n",
    "    (LinearRegression(), \"Linear Regression\"),\n",
    "    (Ridge(alpha=1.0), \"Ridge Regression\"),\n",
    "    (RandomForestRegressor(n_estimators=100, random_state=42), \"Random Forest\"),\n",
    "    (GradientBoostingRegressor(n_estimators=100, random_state=42), \"Gradient Boosting\"),\n",
    "    (xgb.XGBRegressor(n_estimators=100, random_state=42), \"XGBoost\")\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "for model, model_name in models:\n",
    "    result = train_and_evaluate_model(model, model_name, X_train_scaled, y_train, X_test_scaled, y_test, energy_tracker)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Visualization\n",
    "\n",
    "Let's compare the models based on both performance and sustainability metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a dataframe with results\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': r['model_name'],\n",
    "        'RMSE': r['rmse'],\n",
    "        'MAE': r['mae'],\n",
    "        'R²': r['r2'],\n",
    "        'Training Time (s)': r['training_time'],\n",
    "        'Energy (kWh)': r['energy_consumption'],\n",
    "        'Carbon (kg CO2)': r['carbon_footprint'],\n",
    "        'Model Size (KB)': r['model_size']\n",
    "    } for r in results\n",
    "])\n",
    "\n",
    "# Display results table\n",
    "print(\"Model Comparison:\")\n",
    "display(results_df)\n",
    "\n",
    "# Plot performance metrics\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# RMSE\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='Model', y='RMSE', data=results_df, palette='Blues_d')\n",
    "plt.title('RMSE by Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='Model', y='MAE', data=results_df, palette='Blues_d')\n",
    "plt.title('MAE by Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# R²\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='Model', y='R²', data=results_df, palette='Blues_d')\n",
    "plt.title('R² by Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot sustainability metrics\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Training Time\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(x='Model', y='Training Time (s)', data=results_df, palette='Greens_d')\n",
    "plt.title('Training Time by Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Energy Consumption\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(x='Model', y='Energy (kWh)', data=results_df, palette='Greens_d')\n",
    "plt.title('Energy Consumption by Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Carbon Footprint\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='Model', y='Carbon (kg CO2)', data=results_df, palette='Greens_d')\n",
    "plt.title('Carbon Footprint by Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot performance vs. sustainability\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(results_df['Energy (kWh)'], results_df['RMSE'], s=100, alpha=0.7)\n",
    "\n",
    "# Add model names as labels\n",
    "for i, model in enumerate(results_df['Model']):\n",
    "    plt.annotate(model, \n",
    "                 (results_df['Energy (kWh)'].iloc[i], results_df['RMSE'].iloc[i]),\n",
    "                 xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Energy Consumption (kWh)')\n",
    "plt.ylabel('RMSE (Error)')\n",
    "plt.title('Performance vs. Energy Consumption')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretability with SHAP\n",
    "\n",
    "Let's use SHAP values to interpret the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find the best model based on R²\n",
    "best_model_idx = results_df['R²'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "best_model = results[best_model_idx]['model']\n",
    "\n",
    "print(f\"Best model based on R²: {best_model_name}\")\n",
    "\n",
    "# Create SHAP explainer\n",
    "if best_model_name in [\"Random Forest\", \"Gradient Boosting\", \"XGBoost\"]:\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "else:\n",
    "    explainer = shap.LinearExplainer(best_model, X_train_scaled)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# Plot SHAP summary\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, feature_names=features)\n",
    "plt.title(f\"SHAP Feature Importance for {best_model_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot SHAP dependence plots for top features\n",
    "# Get feature importance\n",
    "feature_importance = np.abs(shap_values).mean(0)\n",
    "feature_importance_df = pd.DataFrame(list(zip(features, feature_importance)), columns=['Feature', 'Importance'])\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot dependence plots for top 3 features\n",
    "top_features = feature_importance_df['Feature'].head(3).tolist()\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    feature_idx = features.index(feature)\n",
    "    shap.dependence_plot(feature_idx, shap_values, X_test, feature_names=features)\n",
    "    plt.title(f\"SHAP Dependence Plot for {feature}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sustainable Model Optimization\n",
    "\n",
    "Let's optimize the best model for better sustainability while maintaining performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to calculate sustainability score\n",
    "def calculate_sustainability_score(energy, carbon, model_size, training_time):\n",
    "    # Normalize values (lower is better)\n",
    "    energy_norm = 1 / (1 + energy * 1000)  # Scale up for better differentiation\n",
    "    carbon_norm = 1 / (1 + carbon * 1000)  # Scale up for better differentiation\n",
    "    size_norm = 1 / (1 + model_size / 1000)  # Convert to MB for scaling\n",
    "    time_norm = 1 / (1 + training_time / 10)  # Scale for better differentiation\n",
    "    \n",
    "    # Calculate weighted score (higher is better)\n",
    "    score = 0.4 * energy_norm + 0.3 * carbon_norm + 0.2 * size_norm + 0.1 * time_norm\n",
    "    return score * 100  # Scale to 0-100\n",
    "\n",
    "# Add sustainability score to results\n",
    "results_df['Sustainability Score'] = results_df.apply(\n",
    "    lambda row: calculate_sustainability_score(\n",
    "        row['Energy (kWh)'], \n",
    "        row['Carbon (kg CO2)'], \n",
    "        row['Model Size (KB)'], \n",
    "        row['Training Time (s)']\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate combined score (performance + sustainability)\n",
    "results_df['Combined Score'] = results_df.apply(\n",
    "    lambda row: 0.7 * row['R²'] * 100 + 0.3 * row['Sustainability Score'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display updated results\n",
    "print(\"Model Comparison with Sustainability Scores:\")\n",
    "display(results_df.sort_values('Combined Score', ascending=False))\n",
    "\n",
    "# Plot combined scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_sorted = results_df.sort_values('Combined Score', ascending=False)\n",
    "bars = plt.bar(results_sorted['Model'], results_sorted['Combined Score'], color='teal')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'{height:.2f}',\n",
    "            ha='center', va='bottom', rotation=0)\n",
    "\n",
    "plt.title('Combined Performance and Sustainability Score by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Combined Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the Most Sustainable Model\n",
    "\n",
    "Let's optimize the model with the best combined score for even better sustainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find the model with the best combined score\n",
    "best_combined_idx = results_df['Combined Score'].idxmax()\n",
    "best_combined_model_name = results_df.loc[best_combined_idx, 'Model']\n",
    "print(f\"Model with best combined score: {best_combined_model_name}\")\n",
    "\n",
    "# Define optimization parameters based on the best model\n",
    "if best_combined_model_name == \"Linear Regression\" or best_combined_model_name == \"Ridge Regression\":\n",
    "    # For linear models, we can't do much optimization for sustainability\n",
    "    print(\"Linear models are already quite sustainable. No further optimization needed.\")\n",
    "    optimized_model = results[best_combined_idx]['model']\n",
    "    \n",
    "elif best_combined_model_name == \"Random Forest\":\n",
    "    print(\"Optimizing Random Forest for sustainability...\")\n",
    "    \n",
    "    # Start energy tracking\n",
    "    energy_tracker.start_tracking()\n",
    "    \n",
    "    # Define parameter grid focusing on sustainability\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],  # Fewer trees for efficiency\n",
    "        'max_depth': [10, 15, None],  # Control model complexity\n",
    "        'min_samples_split': [2, 5, 10],  # Prevent overfitting\n",
    "        'min_samples_leaf': [1, 2, 4]  # Prevent overfitting\n",
    "    }\n",
    "    \n",
    "    # Create base model\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # Create optimized model\n",
    "    optimized_model = RandomForestRegressor(random_state=42, **best_params)\n",
    "    optimized_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Stop energy tracking\n",
    "    energy_metrics = energy_tracker.stop_tracking()\n",
    "    \n",
    "elif best_combined_model_name == \"Gradient Boosting\":\n",
    "    print(\"Optimizing Gradient Boosting for sustainability...\")\n",
    "    \n",
    "    # Start energy tracking\n",
    "    energy_tracker.start_tracking()\n",
    "    \n",
    "    # Define parameter grid focusing on sustainability\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],  # Fewer trees for efficiency\n",
    "        'max_depth': [3, 5, 7],  # Shallower trees for efficiency\n",
    "        'learning_rate': [0.05, 0.1, 0.2],  # Control convergence speed\n",
    "        'subsample': [0.8, 1.0]  # Use subsampling for efficiency\n",
    "    }\n",
    "    \n",
    "    # Create base model\n",
    "    gb = GradientBoostingRegressor(random_state=42)\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(gb, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # Create optimized model\n",
    "    optimized_model = GradientBoostingRegressor(random_state=42, **best_params)\n",
    "    optimized_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Stop energy tracking\n",
    "    energy_metrics = energy_tracker.stop_tracking()\n",
    "    \n",
    "elif best_combined_model_name == \"XGBoost\":\n",
    "    print(\"Optimizing XGBoost for sustainability...\")\n",
    "    \n",
    "    # Start energy tracking\n",
    "    energy_tracker.start_tracking()\n",
    "    \n",
    "    # Define parameter grid focusing on sustainability\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],  # Fewer trees for efficiency\n",
    "        'max_depth': [3, 5, 7],  # Shallower trees for efficiency\n",
    "        'learning_rate': [0.05, 0.1, 0.2],  # Control convergence speed\n",
    "        'subsample': [0.8, 1.0],  # Use subsampling for efficiency\n",
    "        'colsample_bytree': [0.8, 1.0]  # Use feature subsampling for efficiency\n",
    "    }\n",
    "    \n",
    "    # Create base model\n",
    "    xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    # Create optimized model\n",
    "    optimized_model = xgb.XGBRegressor(random_state=42, **best_params)\n",
    "    optimized_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Stop energy tracking\n",
    "    energy_metrics = energy_tracker.stop_tracking()\n",
    "\n",
    "# Evaluate optimized model\n",
    "if best_combined_model_name not in [\"Linear Regression\", \"Ridge Regression\"]:\n",
    "    # Make predictions\n",
    "    y_pred = optimized_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate carbon footprint\n",
    "    carbon_footprint = energy_tracker.get_carbon_footprint(region='global', renewable_percentage=20)\n",
    "    \n",
    "    # Calculate model size\n",
    "    import sys\n",
    "    model_size_bytes = sys.getsizeof(optimized_model)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nOptimized Model Performance:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nOptimized Model Sustainability:\")\n",
    "    print(f\"Training Time: {energy_metrics['duration_seconds']:.4f} seconds\")\n",
    "    print(f\"Energy Consumption: {energy_metrics['energy_consumption_kwh']:.6f} kWh\")\n",
    "    print(f\"Carbon Footprint: {carbon_footprint:.6f} kg CO2eq\")\n",
    "    print(f\"Model Size: {model_size_bytes / 1024:.2f} KB\")\n",
    "    \n",
    "    # Calculate sustainability score\n",
    "    sustainability_score = calculate_sustainability_score(\n",
    "        energy_metrics['energy_consumption_kwh'],\n",
    "        carbon_footprint,\n",
    "        model_size_bytes / 1024,\n",
    "        energy_metrics['duration_seconds']\n",
    "    )\n",
    "    \n",
    "    # Calculate combined score\n",
    "    combined_score = 0.7 * r2 * 100 + 0.3 * sustainability_score\n",
    "    \n",
    "    print(f\"\\nSustainability Score: {sustainability_score:.2f}\")\n",
    "    print(f\"Combined Score: {combined_score:.2f}\")\n",
    "    \n",
    "    # Compare with original model\n",
    "    original_combined_score = results_df.loc[best_combined_idx, 'Combined Score']\n",
    "    improvement = combined_score - original_combined_score\n",
    "    \n",
    "    print(f\"\\nImprovement over original model: {improvement:.2f} points ({improvement/original_combined_score*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation and Visualization\n",
    "\n",
    "Let's evaluate the final optimized model and visualize its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions with the final model\n",
    "final_model = optimized_model if 'optimized_model' in locals() else results[best_combined_idx]['model']\n",
    "final_model_name = f\"Optimized {best_combined_model_name}\" if 'optimized_model' in locals() else best_combined_model_name\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Energy Consumption')\n",
    "plt.ylabel('Predicted Energy Consumption')\n",
    "plt.title(f'Actual vs Predicted Energy Consumption ({final_model_name})')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Energy Consumption')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title(f'Residual Plot ({final_model_name})')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importance for the final model\n",
    "if hasattr(final_model, 'feature_importances_'):\n",
    "    # For tree-based models\n",
    "    importances = final_model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(f'Feature Importance ({final_model_name})')\n",
    "    plt.bar(range(X_train.shape[1]), importances[indices], align='center')\n",
    "    plt.xticks(range(X_train.shape[1]), [features[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "elif hasattr(final_model, 'coef_'):\n",
    "    # For linear models\n",
    "    coefficients = final_model.coef_\n",
    "    importance = np.abs(coefficients)\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(f'Feature Coefficients ({final_model_name})')\n",
    "    plt.bar(range(X_train.shape[1]), coefficients[indices], align='center')\n",
    "    plt.xticks(range(X_train.shape[1]), [features[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Consumption Tracking Visualization\n",
    "\n",
    "Let's visualize the energy consumption during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot energy consumption history\n",
    "energy_tracker.plot_energy_consumption()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Sustainability Report\n",
    "\n",
    "Let's summarize our findings and generate a sustainability report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate sustainability report\n",
    "print(\"=\"*80)\n",
    "print(\"                        SUSTAINABLE AI MODEL REPORT                        \")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nModel: {final_model_name}\")\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUSTAINABILITY METRICS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if 'optimized_model' in locals():\n",
    "    print(f\"Training Time: {energy_metrics['duration_seconds']:.4f} seconds\")\n",
    "    print(f\"Energy Consumption: {energy_metrics['energy_consumption_kwh']:.6f} kWh\")\n",
    "    print(f\"Carbon Footprint: {carbon_footprint:.6f} kg CO2eq\")\n",
    "    print(f\"Model Size: {model_size_bytes / 1024:.2f} KB\")\n",
    "else:\n",
    "    result = results[best_combined_idx]\n",
    "    print(f\"Training Time: {result['training_time']:.4f} seconds\")\n",
    "    print(f\"Energy Consumption: {result['energy_consumption']:.6f} kWh\")\n",
    "    print(f\"Carbon Footprint: {result['carbon_footprint']:.6f} kg CO2eq\")\n",
    "    print(f\"Model Size: {result['model_size']:.2f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ENVIRONMENTAL IMPACT EQUIVALENTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate equivalents\n",
    "if 'optimized_model' in locals():\n",
    "    carbon_kg = carbon_footprint\n",
    "else:\n",
    "    carbon_kg = results[best_combined_idx]['carbon_footprint']\n",
    "\n",
    "# Car driving equivalent (120g CO2 per km)\n",
    "car_km = carbon_kg / 0.12\n",
    "print(f\"Car Driving: {car_km:.2f} km\")\n",
    "\n",
    "# Smartphone charging equivalent (0.005 kWh per charge, ~1g CO2)\n",
    "smartphone_charges = carbon_kg / 0.001\n",
    "print(f\"Smartphone Charges: {smartphone_charges:.2f} charges\")\n",
    "\n",
    "# LED light bulb equivalent (10W, 0.01 kWh per hour, ~2g CO2)\n",
    "led_hours = carbon_kg / 0.002\n",
    "print(f\"LED Light Bulb: {led_hours:.2f} hours\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SUSTAINABILITY RECOMMENDATIONS\")\n",
    "print(\"-\"*80)\n",
    "print(\"1. Consider using simpler models for tasks where high accuracy is not critical\")\n",
    "print(\"2. Implement early stopping to reduce unnecessary training iterations\")\n",
    "print(\"3. Use feature selection to reduce model complexity and improve efficiency\")\n",
    "print(\"4. Train models in regions with lower carbon intensity electricity\")\n",
    "print(\"5. Consider using renewable energy sources for model training and deployment\")\n",
    "print(\"6. Regularly monitor and optimize model performance and energy consumption\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"-\"*80)\n",
    "display(results_df[['Model', 'RMSE', 'R²', 'Energy (kWh)', 'Carbon (kg CO2)', 'Combined Score']].sort_values('Combined Score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Final Model\n",
    "\n",
    "Let's save the final model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model and scaler\n",
    "import pickle\n",
    "\n",
    "# Save model\n",
    "with open('sustainable_energy_model.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "# Save scaler\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save feature list\n",
    "with open('features.pkl', 'wb') as f:\n",
    "    pickle.dump(features, f)\n",
    "\n",
    "print(\"Model and associated files saved successfully!\")\n",
    "\n",
    "# Download the files\n",
    "from google.colab import files\n",
    "files.download('sustainable_energy_model.pkl')\n",
    "files.download('scaler.pkl')\n",
    "files.download('features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Prediction Function\n",
    "\n",
    "Here's a function to make predictions with the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_energy_consumption(input_data, model, scaler, feature_list):\n",
    "    \"\"\"\n",
    "    Make energy consumption predictions using the trained model.\n",
    "    \n",
    "    Args:\n",
    "        input_data: DataFrame with the required features\n",
    "        model: Trained model\n",
    "        scaler: Fitted scaler\n",
    "        feature_list: List of features used by the model\n",
    "        \n",
    "    Returns:\n",
    "        Predicted energy consumption\n",
    "    \"\"\"\n",
    "    # Ensure input data has all required features\n",
    "    for feature in feature_list:\n",
    "        if feature not in input_data.columns:\n",
    "            raise ValueError(f\"Missing feature: {feature}\")\n",
    "    \n",
    "    # Extract features in the correct order\n",
    "    X = input_data[feature_list].values\n",
    "    \n",
    "    # Scale features\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(X_scaled)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "# Create sample input data\n",
    "sample_input = X_test.iloc[:5].copy()\n",
    "\n",
    "# Make predictions\n",
    "sample_predictions = predict_energy_consumption(sample_input, final_model, scaler, features)\n",
    "\n",
    "# Display results\n",
    "print(\"Sample Predictions:\")\n",
    "for i, pred in enumerate(sample_predictions):\n",
    "    actual = y_test.iloc[i]\n",
    "    print(f\"Sample {i+1}: Predicted = {pred:.4f} kWh, Actual = {actual:.4f} kWh, Error = {abs(pred - actual):.4f} kWh\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
